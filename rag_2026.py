# -*- coding: utf-8 -*-
"""RAG_2026.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F7lCTL9lrWsQGHXTORmmbQE48tgoaUWV
"""

# ===============================
# STEP 0: Install Libraries
# ===============================
!pip install -q youtube-transcript-api langchain langchain-community langchain-openai faiss-cpu tiktoken python-dotenv

# ===============================
# STEP 0.1: Import & API Key
# ===============================
import os

os.environ["OPENAI_API_KEY"] = "YOUR_OPENAI_API_KEY"  # üî¥ yaha apni key daalo

!pip uninstall -y youtube-transcript-api
!pip install --upgrade youtube-transcript-api

!pip install pytube

from pytube import YouTube

yt = YouTube("https://www.youtube.com/watch?v=ILrYwPd1Dc")

caption = yt.captions.get_by_language_code('en')
if caption:
    text = caption.generate_srt_captions()
    print(text[:1000])
else:
    print("‚ùå English captions available nahi hain")

# ===============================
# STEP 2: Split Text into Chunks
# ===============================
from langchain.text_splitter import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)

documents = text_splitter.create_documents([transcript_text])

print(f"Total Chunks: {len(documents)}")
print(documents[0])

# ===============================
# STEP 3: Create Embeddings & Store in FAISS
# ===============================
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small"
)

vector_store = FAISS.from_documents(documents, embeddings)

# ===============================
# STEP 4: Create Retriever
# ===============================
retriever = vector_store.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 4}
)

retriever

# ===============================
# STEP 5: Prompt Template
# ===============================
from langchain_core.prompts import PromptTemplate

prompt = PromptTemplate(
    template="""
You are a helpful assistant.
Answer ONLY from the provided transcript context.
If the context is insufficient, say "I don't know".

Context:
{context}

Question:
{question}
""",
    input_variables=["context", "question"]
)

# ===============================
# STEP 6: LLM
# ===============================
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0.2
)

# ===============================
# STEP 7: RAG Chain
# ===============================
from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda
from langchain_core.output_parsers import StrOutputParser

def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

rag_chain = (
    RunnableParallel({
        "context": retriever | RunnableLambda(format_docs),
        "question": RunnablePassthrough()
    })
    | prompt
    | llm
    | StrOutputParser()
)

# ===============================
# STEP 8: Ask Questions
# ===============================
rag_chain.invoke("Who is Demis Hassabis?")

rag_chain.invoke("Is nuclear fusion discussed in this video?")

rag_chain.invoke("Can you summarize the video?")

YouTube Video
   ‚Üì
Transcript
   ‚Üì
Chunking
   ‚Üì
Embeddings
   ‚Üì
FAISS Vector DB
   ‚Üì
Retriever
   ‚Üì
Prompt Augmentation
   ‚Üì
LLM
   ‚Üì
Answer